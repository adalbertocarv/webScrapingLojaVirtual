# **ğŸ“– DocumentaÃ§Ã£o - Web Scraper para Yupoo**
## **ğŸ“Œ DescriÃ§Ã£o**
Projeto Ã© um **web scraper** desenvolvido em **Node.js** com **Selenium WebDriver**. Ele acessa a pÃ¡gina da loja **Yupoo**, coleta os links dos Ã¡lbuns, acessa cada um deles e captura **screenshots das imagens** disponÃ­veis.

O scraper **navega automaticamente** pelos Ã¡lbuns, tira **prints das miniaturas e imagens grandes**, e salva todas as capturas em **pastas organizadas**.

---

## **ğŸ“‚ Estrutura do Projeto**
```
yupoo_scraper/
â”‚â”€â”€ scraping.js         # CÃ³digo principal do web scraper
â”‚â”€â”€ package.json        # Arquivo de configuraÃ§Ã£o do Node.js
â”‚â”€â”€ README.md           # DocumentaÃ§Ã£o do projeto
â”‚â”€â”€ imagens-salvas/  # Pasta onde as imagens capturadas serÃ£o salvas
â”‚   â”‚â”€â”€ album_1/
â”‚   â”‚   â”œâ”€â”€ screenshot_miniatura_1.png
â”‚   â”‚   â”œâ”€â”€ screenshot_grande_1.png
â”‚   â”‚â”€â”€ album_2/
â”‚   â”‚   â”œâ”€â”€ screenshot_miniatura_1.png
â”‚   â”‚   â”œâ”€â”€ screenshot_grande_1.png
```

---

## **ğŸ› ï¸ Tecnologias Utilizadas**
- **Node.js** â†’ Plataforma para executar JavaScript no backend
- **Selenium WebDriver** â†’ Biblioteca para automaÃ§Ã£o de navegador
- **ChromeDriver** â†’ Driver para controlar o Google Chrome
- **fs-extra** â†’ Biblioteca para manipulaÃ§Ã£o de arquivos e diretÃ³rios

---

## **ğŸ“¦ InstalaÃ§Ã£o**
### 1ï¸âƒ£ **Clonar o repositÃ³rio**
```sh
git clone https://github.com/seu-usuario/yupoo-scraper.git
cd yupoo-scraper
```

### 2ï¸âƒ£ **Instalar as dependÃªncias**
```sh
npm install
```

Isso instalarÃ¡:
- **selenium-webdriver** â†’ Para automaÃ§Ã£o do navegador
- **fs-extra** â†’ Para manipulaÃ§Ã£o de arquivos
- **chromedriver** â†’ Driver para o Chrome

Se ainda nÃ£o tiver o ChromeDriver instalado, execute:
```sh
npm install chromedriver --save
```

---

## **ğŸš€ Como Executar**
Para rodar o scraper:
```sh
node scraping.js
```
Ele abrirÃ¡ o navegador em **modo headless**, coletarÃ¡ os links dos Ã¡lbuns e capturarÃ¡ **screenshots das imagens**.

---

## **âš™ï¸ Como Funciona?**
### **1ï¸âƒ£ ConfiguraÃ§Ã£o do Selenium**
No inÃ­cio do cÃ³digo, configuramos o Selenium para rodar **em segundo plano** (`headless`), otimizando o desempenho:
```javascript
const options = new chrome.Options();
options.addArguments("--headless=new"); // Modo headless atualizado
options.addArguments("--disable-gpu");
options.addArguments("--disable-software-rasterizer");
options.addArguments("--disable-extensions");
options.addArguments("--disable-dev-shm-usage");
```

---

### **2ï¸âƒ£ Acessando a PÃ¡gina Inicial**
O scraper acessa a **pÃ¡gina de Ã¡lbuns da Yupoo** e coleta todos os links:
```javascript
await driver.get(base_url);
await driver.sleep(3000);

const produtos = await driver.findElements(By.css("a.album__main"));
let prodLinks = [];

for (let produto of produtos) {
    let link = await produto.getAttribute("href");
    prodLinks.push(link);
}
```

---

### **3ï¸âƒ£ Capturando Screenshots das Miniaturas**
Cada Ã¡lbum tem vÃ¡rias imagens **miniaturas**, que sÃ£o capturadas e salvas:
```javascript
let imagens = await driver.findElements(By.css("img.image__img"));

for (let idx = 0; idx < imagens.length; idx++) {
    let imgPath = path.join(produtoDir, `screenshot_miniatura_${idx + 1}.png`);
    await imagens[idx].takeScreenshot().then((data) => {
        fs.writeFileSync(imgPath, data, "base64");
    });

    console.log(`âœ… Screenshot da miniatura ${idx + 1} salva em: ${imgPath}`);
}
```

---

### **4ï¸âƒ£ Acessando a Imagem Maior**
ApÃ³s clicar na miniatura, o Selenium espera a **imagem grande carregar**:
```javascript
let botoesVerDetalhe = await driver.findElements(By.css("div.image__clickhandle"));
await driver.executeScript("arguments[0].click();", botoesVerDetalhe[idx]);
await driver.sleep(3000);

await driver.wait(until.elementLocated(By.css("div.viewer__imagewrap img.viewer__img")), 10000);
```

---

### **5ï¸âƒ£ Capturando a Imagem Maior**
O Selenium entÃ£o **tira um print da imagem grande**:
```javascript
let imgGrandeElement = await driver.findElement(By.css("div.viewer__imagewrap img.viewer__img"));
let imgGrandePath = path.join(produtoDir, `screenshot_grande_${idx + 1}.png`);
await imgGrandeElement.takeScreenshot().then((data) => {
    fs.writeFileSync(imgGrandePath, data, "base64");
});

console.log(`âœ… Screenshot da imagem grande ${idx + 1} salva em: ${imgGrandePath}`);
```

---

### **6ï¸âƒ£ Fechando a Imagem e Continuando**
Antes de seguir para a prÃ³xima imagem, o Selenium **fecha a imagem expandida**:
```javascript
let botaoFechar = await driver.findElement(By.css("a#viewer__close"));
await driver.executeScript("arguments[0].click();", botaoFechar);
await driver.sleep(2000);
```

---

## **ğŸ“Œ PersonalizaÃ§Ã£o**
### **âœ… Definir a Quantidade de Ãlbuns**
Se quiser capturar mais Ã¡lbuns, altere:
```javascript
for (let index = 0; index < Math.min(5, prodLinks.length); index++) {
```
Mude **5** para o nÃºmero desejado.

---

### **âœ… Alterar o Tempo de Espera**
O tempo de espera padrÃ£o Ã© de **3 segundos**. Para aumentar/diminuir:
```javascript
await driver.sleep(3000); // 3 segundos
```

---

## **ğŸ” PossÃ­veis Erros e SoluÃ§Ãµes**
| Erro | SoluÃ§Ã£o |
|------|---------|
| `chromedriver not found` | Execute `npm install chromedriver --save` |
| `ElementClickInterceptedError` | O site pode estar carregando lentamente, aumente `await driver.sleep(3000);` |
| `TimeoutError: Waiting for element...` | Verifique se o seletor CSS das imagens ainda Ã© vÃ¡lido |

---

## **ğŸ“Œ ContribuiÃ§Ãµes**
Se quiser contribuir:
1. **FaÃ§a um Fork** do repositÃ³rio
2. **Crie uma branch** para sua feature:
   ```sh
   git checkout -b minha-feature
   ```
3. **FaÃ§a commit das alteraÃ§Ãµes**
   ```sh
   git commit -m "Adicionei uma nova feature"
   ```
4. **Envie para o repositÃ³rio**
   ```sh
   git push origin minha-feature
   ```

---

## **ğŸ“œ LicenÃ§a**
Este projeto Ã© distribuÃ­do sob a licenÃ§a **MIT**.

---

## **ğŸ¯ ConclusÃ£o**
Este **web scraper** permite coletar **screenshots automaticamente** dos Ã¡lbuns do **Yupoo** de maneira eficiente. Ele pode ser expandido para:
- **Baixar imagens automaticamente**.
- **Capturar informaÃ§Ãµes adicionais (preÃ§o, descriÃ§Ã£o, etc.)**.
- **Integrar com uma API para armazenar dados**.

Agora vocÃª pode rodar o scraper e capturar todas as imagens que precisar! ğŸš€